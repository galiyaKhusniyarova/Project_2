{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ab12355-2d86-4ee5-b71c-476855263a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df3e9a-dcb8-4225-ab45-9a030b3785df",
   "metadata": {},
   "source": [
    "### Read realtor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcb93420-f06e-494e-bf44-1a97f5b0995b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sold_date</th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>full_address</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15 William St, North Arlington, NJ, 07031</td>\n",
       "      <td>15 William St</td>\n",
       "      <td>North Arlington</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7031.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>234900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>185 Gilsum St, Keene, NH, 03431</td>\n",
       "      <td>185 Gilsum St</td>\n",
       "      <td>Keene</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>3431.0</td>\n",
       "      <td>1752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>234900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>185 Gilsum St, Keene, NH, 03431</td>\n",
       "      <td>185 Gilsum St</td>\n",
       "      <td>Keene</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>3431.0</td>\n",
       "      <td>1752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>1245000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57 Reade St Apt 5D, New York, NY, 10007</td>\n",
       "      <td>57 Reade St Apt 5D</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>10007.0</td>\n",
       "      <td>785.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>234900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>185 Gilsum St, Keene, NH, 03431</td>\n",
       "      <td>185 Gilsum St</td>\n",
       "      <td>Keene</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>3431.0</td>\n",
       "      <td>1752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25191</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>389000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62 Park Ter W Apt A26, New York, NY, 10034</td>\n",
       "      <td>62 Park Ter W Apt A26</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>10034.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25192</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>3995000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200 E 62nd St Apt 14E, New York, NY, 10065</td>\n",
       "      <td>200 E 62nd St Apt 14E</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>10065.0</td>\n",
       "      <td>1936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25193</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>399000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1 Mayer Ln, Pomona, NY, 10970</td>\n",
       "      <td>1 Mayer Ln</td>\n",
       "      <td>Pomona</td>\n",
       "      <td>New York</td>\n",
       "      <td>10970.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25194</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>3475000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200 Mercer St Apt 4E, New York City, NY, 10012</td>\n",
       "      <td>200 Mercer St Apt 4E</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York</td>\n",
       "      <td>10012.0</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25195</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>3995000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200 E 62nd St Apt 14E, New York, NY, 10065</td>\n",
       "      <td>200 E 62nd St Apt 14E</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>10065.0</td>\n",
       "      <td>1936.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25196 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sold_date    status      price  bed  bath  acre_lot  \\\n",
       "0      2018-01-02  for_sale   450000.0  3.0   2.0      0.09   \n",
       "1      2018-01-02  for_sale   234900.0  3.0   2.0      0.87   \n",
       "2      2018-01-02  for_sale   234900.0  3.0   2.0      0.87   \n",
       "3      2018-01-02  for_sale  1245000.0  1.0   1.0       NaN   \n",
       "4      2018-01-02  for_sale   234900.0  3.0   2.0      0.87   \n",
       "...           ...       ...        ...  ...   ...       ...   \n",
       "25191  2018-12-31  for_sale   389000.0  1.0   1.0       NaN   \n",
       "25192  2018-12-31  for_sale  3995000.0  2.0   3.0       NaN   \n",
       "25193  2018-12-31  for_sale   399000.0  NaN   NaN      1.15   \n",
       "25194  2018-12-31  for_sale  3475000.0  2.0   2.0       NaN   \n",
       "25195  2018-12-31  for_sale  3995000.0  2.0   3.0       NaN   \n",
       "\n",
       "                                         full_address                 street  \\\n",
       "0           15 William St, North Arlington, NJ, 07031          15 William St   \n",
       "1                     185 Gilsum St, Keene, NH, 03431          185 Gilsum St   \n",
       "2                     185 Gilsum St, Keene, NH, 03431          185 Gilsum St   \n",
       "3             57 Reade St Apt 5D, New York, NY, 10007     57 Reade St Apt 5D   \n",
       "4                     185 Gilsum St, Keene, NH, 03431          185 Gilsum St   \n",
       "...                                               ...                    ...   \n",
       "25191      62 Park Ter W Apt A26, New York, NY, 10034  62 Park Ter W Apt A26   \n",
       "25192      200 E 62nd St Apt 14E, New York, NY, 10065  200 E 62nd St Apt 14E   \n",
       "25193                   1 Mayer Ln, Pomona, NY, 10970             1 Mayer Ln   \n",
       "25194  200 Mercer St Apt 4E, New York City, NY, 10012   200 Mercer St Apt 4E   \n",
       "25195      200 E 62nd St Apt 14E, New York, NY, 10065  200 E 62nd St Apt 14E   \n",
       "\n",
       "                  city          state  zip_code  house_size  \n",
       "0      North Arlington     New Jersey    7031.0         NaN  \n",
       "1                Keene  New Hampshire    3431.0      1752.0  \n",
       "2                Keene  New Hampshire    3431.0      1752.0  \n",
       "3             New York       New York   10007.0       785.0  \n",
       "4                Keene  New Hampshire    3431.0      1752.0  \n",
       "...                ...            ...       ...         ...  \n",
       "25191         New York       New York   10034.0       800.0  \n",
       "25192         New York       New York   10065.0      1936.0  \n",
       "25193           Pomona       New York   10970.0         NaN  \n",
       "25194    New York City       New York   10012.0      2500.0  \n",
       "25195         New York       New York   10065.0      1936.0  \n",
       "\n",
       "[25196 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "realtor_2018_data = pd.read_csv(\n",
    "    Path(\"realtor_data/2018_realtor_data.csv\"))\n",
    "realtor_2019_data = pd.read_csv(\n",
    "    Path(\"realtor_data/2019_realtor_data.csv\"))\n",
    "display(realtor_2018_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cdb4222-913f-4b27-bb00-850d35c85d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['realtor_data\\\\2018_realtor_data.csv', 'realtor_data\\\\2019_realtor_data.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = glob.glob('realtor_data/*')\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a048e19-3d0c-48f9-a5b5-de04cef31128",
   "metadata": {},
   "source": [
    "### Merge realtor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3dc99db-82b1-4e6f-98da-df58b84c8d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria Angels Bonany\\AppData\\Local\\Temp\\ipykernel_1604\\2874440782.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  realtor_data = realtor_data.append(df_temp)\n",
      "C:\\Users\\Maria Angels Bonany\\AppData\\Local\\Temp\\ipykernel_1604\\2874440782.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  realtor_data = realtor_data.append(df_temp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sold_date</th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>full_address</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>house_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7031.0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15 William St, North Arlington, NJ, 07031</td>\n",
       "      <td>15 William St</td>\n",
       "      <td>North Arlington</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431.0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>234900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>185 Gilsum St, Keene, NH, 03431</td>\n",
       "      <td>185 Gilsum St</td>\n",
       "      <td>Keene</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>1752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431.0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>234900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>185 Gilsum St, Keene, NH, 03431</td>\n",
       "      <td>185 Gilsum St</td>\n",
       "      <td>Keene</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>1752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007.0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>1245000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57 Reade St Apt 5D, New York, NY, 10007</td>\n",
       "      <td>57 Reade St Apt 5D</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>785.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431.0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>234900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>185 Gilsum St, Keene, NH, 03431</td>\n",
       "      <td>185 Gilsum St</td>\n",
       "      <td>Keene</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>1752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450.0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>259900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>20 Russell Rd, Meriden, CT, 06450</td>\n",
       "      <td>20 Russell Rd</td>\n",
       "      <td>Meriden</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6112.0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>299999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.18</td>\n",
       "      <td>439 Edgewood St, Hartford, CT, 06112</td>\n",
       "      <td>439 Edgewood St</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>3922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127.0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>1598000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57 L St Apt 10, Boston, MA, 02127</td>\n",
       "      <td>57 L St Apt 10</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1574.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127.0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>1598000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57 L St Apt 10, Boston, MA, 02127</td>\n",
       "      <td>57 L St Apt 10</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1574.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086.0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>919000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 Shippen St, Weehawken, NJ, 07086</td>\n",
       "      <td>5 Shippen St</td>\n",
       "      <td>Weehawken</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49623 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sold_date    status      price  bed  bath  acre_lot  \\\n",
       "zip_code                                                         \n",
       "7031.0    2018-01-02  for_sale   450000.0  3.0   2.0      0.09   \n",
       "3431.0    2018-01-02  for_sale   234900.0  3.0   2.0      0.87   \n",
       "3431.0    2018-01-02  for_sale   234900.0  3.0   2.0      0.87   \n",
       "10007.0   2018-01-02  for_sale  1245000.0  1.0   1.0       NaN   \n",
       "3431.0    2018-01-02  for_sale   234900.0  3.0   2.0      0.87   \n",
       "...              ...       ...        ...  ...   ...       ...   \n",
       "6450.0    2019-12-31  for_sale   259900.0  3.0   2.0      0.18   \n",
       "6112.0    2019-12-31  for_sale   299999.0  NaN   NaN      0.18   \n",
       "2127.0    2019-12-31  for_sale  1598000.0  3.0   2.0       NaN   \n",
       "2127.0    2019-12-31  for_sale  1598000.0  3.0   2.0       NaN   \n",
       "7086.0    2019-12-31  for_sale   919000.0  4.0   2.0       NaN   \n",
       "\n",
       "                                       full_address              street  \\\n",
       "zip_code                                                                  \n",
       "7031.0    15 William St, North Arlington, NJ, 07031       15 William St   \n",
       "3431.0              185 Gilsum St, Keene, NH, 03431       185 Gilsum St   \n",
       "3431.0              185 Gilsum St, Keene, NH, 03431       185 Gilsum St   \n",
       "10007.0     57 Reade St Apt 5D, New York, NY, 10007  57 Reade St Apt 5D   \n",
       "3431.0              185 Gilsum St, Keene, NH, 03431       185 Gilsum St   \n",
       "...                                             ...                 ...   \n",
       "6450.0            20 Russell Rd, Meriden, CT, 06450       20 Russell Rd   \n",
       "6112.0         439 Edgewood St, Hartford, CT, 06112     439 Edgewood St   \n",
       "2127.0            57 L St Apt 10, Boston, MA, 02127      57 L St Apt 10   \n",
       "2127.0            57 L St Apt 10, Boston, MA, 02127      57 L St Apt 10   \n",
       "7086.0           5 Shippen St, Weehawken, NJ, 07086        5 Shippen St   \n",
       "\n",
       "                     city          state  house_size  \n",
       "zip_code                                              \n",
       "7031.0    North Arlington     New Jersey         NaN  \n",
       "3431.0              Keene  New Hampshire      1752.0  \n",
       "3431.0              Keene  New Hampshire      1752.0  \n",
       "10007.0          New York       New York       785.0  \n",
       "3431.0              Keene  New Hampshire      1752.0  \n",
       "...                   ...            ...         ...  \n",
       "6450.0            Meriden    Connecticut      1312.0  \n",
       "6112.0           Hartford    Connecticut      3922.0  \n",
       "2127.0             Boston  Massachusetts      1574.0  \n",
       "2127.0             Boston  Massachusetts      1574.0  \n",
       "7086.0          Weehawken     New Jersey         NaN  \n",
       "\n",
       "[49623 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "realtor_data = pd.DataFrame()\n",
    "\n",
    "for file in csv_files:\n",
    "            df_temp = pd.read_csv(file)\n",
    "            realtor_data = realtor_data.append(df_temp)\n",
    "            \n",
    "realtor_data.set_index(\"zip_code\", drop=True, inplace=True)\n",
    "\n",
    "display(realtor_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f334a-e7bf-4ba0-aa2a-ca0f9b242ad7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Merge IRS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa5e2de-1027-4d49-bbcf-5f90d7024cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IRS_Income_tax_data\\\\IRS_2018_data_sliced.csv',\n",
       " 'IRS_Income_tax_data\\\\IRS_2019_data_sliced.csv']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = glob.glob('IRS_Income_tax_data/*.csv')\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e11c107c-4330-4a5d-99f6-bc334ae434de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria Angels Bonany\\AppData\\Local\\Temp\\ipykernel_1604\\4150780073.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  IRS_sliced_data = IRS_sliced_data.append(df_temp, ignore_index=True)\n",
      "C:\\Users\\Maria Angels Bonany\\AppData\\Local\\Temp\\ipykernel_1604\\4150780073.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  IRS_sliced_data = IRS_sliced_data.append(df_temp, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>A18425</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "      <td>2905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "      <td>27454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "      <td>56235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "      <td>60309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "      <td>292798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332089</th>\n",
       "      <td>WY</td>\n",
       "      <td>99999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332090</th>\n",
       "      <td>WY</td>\n",
       "      <td>99999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332091</th>\n",
       "      <td>WY</td>\n",
       "      <td>99999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332092</th>\n",
       "      <td>WY</td>\n",
       "      <td>99999</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332093</th>\n",
       "      <td>WY</td>\n",
       "      <td>99999</td>\n",
       "      <td>942.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332094 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATE  zipcode    A18425\n",
       "0         AL        0    2905.0\n",
       "1         AL        0   27454.0\n",
       "2         AL        0   56235.0\n",
       "3         AL        0   60309.0\n",
       "4         AL        0  292798.0\n",
       "...      ...      ...       ...\n",
       "332089    WY    99999       0.0\n",
       "332090    WY    99999       0.0\n",
       "332091    WY    99999       0.0\n",
       "332092    WY    99999     122.0\n",
       "332093    WY    99999     942.0\n",
       "\n",
       "[332094 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IRS_sliced_data = pd.DataFrame()\n",
    "\n",
    "for file in csv_files:\n",
    "            df_temp = pd.read_csv(file)\n",
    "            IRS_sliced_data = IRS_sliced_data.append(df_temp, ignore_index=True)\n",
    "            \n",
    "display(IRS_sliced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89fe4cc9-516b-4f3b-bc1b-9cfdb106d221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>A18425</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>2905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>27454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>56235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>60309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>292798.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>WY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>WY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>WY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>WY</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>WY</td>\n",
       "      <td>942.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332094 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STATE    A18425\n",
       "zip_code                \n",
       "0           AL    2905.0\n",
       "0           AL   27454.0\n",
       "0           AL   56235.0\n",
       "0           AL   60309.0\n",
       "0           AL  292798.0\n",
       "...        ...       ...\n",
       "99999       WY       0.0\n",
       "99999       WY       0.0\n",
       "99999       WY       0.0\n",
       "99999       WY     122.0\n",
       "99999       WY     942.0\n",
       "\n",
       "[332094 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the Index to zip-code\n",
    "IRS_sliced_data.rename(columns = {'zipcode':'zip_code'}, inplace=True)\n",
    "IRS_sliced_data.set_index('zip_code', drop=True, inplace=True)\n",
    "\n",
    "display(IRS_sliced_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bc69c-2231-40bf-8e96-67006755a627",
   "metadata": {},
   "source": [
    "### Merge realtor and IRS data on zip_code (left join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1bb5b1d-ee46-4630-8539-a69af04b8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = realtor_data.merge(IRS_sliced_data, how = 'left', on = \"zip_code\")\n",
    "df1.drop(columns=[\"state\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd656c1-83da-4d31-91b4-aae58ed6ed6f",
   "metadata": {},
   "source": [
    "## The final DataFrame we are going to work with!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9df6642-c52f-4e89-a77f-d4d7896c9296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sold_date</th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>full_address</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>house_size</th>\n",
       "      <th>STATE</th>\n",
       "      <th>A18425</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7031.0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15 William St, North Arlington, NJ, 07031</td>\n",
       "      <td>15 William St</td>\n",
       "      <td>North Arlington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031.0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15 William St, North Arlington, NJ, 07031</td>\n",
       "      <td>15 William St</td>\n",
       "      <td>North Arlington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031.0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15 William St, North Arlington, NJ, 07031</td>\n",
       "      <td>15 William St</td>\n",
       "      <td>North Arlington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031.0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15 William St, North Arlington, NJ, 07031</td>\n",
       "      <td>15 William St</td>\n",
       "      <td>North Arlington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031.0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>15 William St, North Arlington, NJ, 07031</td>\n",
       "      <td>15 William St</td>\n",
       "      <td>North Arlington</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>1989.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086.0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>919000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 Shippen St, Weehawken, NJ, 07086</td>\n",
       "      <td>5 Shippen St</td>\n",
       "      <td>Weehawken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086.0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>919000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 Shippen St, Weehawken, NJ, 07086</td>\n",
       "      <td>5 Shippen St</td>\n",
       "      <td>Weehawken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086.0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>919000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 Shippen St, Weehawken, NJ, 07086</td>\n",
       "      <td>5 Shippen St</td>\n",
       "      <td>Weehawken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086.0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>919000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 Shippen St, Weehawken, NJ, 07086</td>\n",
       "      <td>5 Shippen St</td>\n",
       "      <td>Weehawken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>3032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086.0</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>919000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 Shippen St, Weehawken, NJ, 07086</td>\n",
       "      <td>5 Shippen St</td>\n",
       "      <td>Weehawken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NJ</td>\n",
       "      <td>24460.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593111 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sold_date    status     price  bed  bath  acre_lot  \\\n",
       "zip_code                                                        \n",
       "7031.0    2018-01-02  for_sale  450000.0  3.0   2.0      0.09   \n",
       "7031.0    2018-01-02  for_sale  450000.0  3.0   2.0      0.09   \n",
       "7031.0    2018-01-02  for_sale  450000.0  3.0   2.0      0.09   \n",
       "7031.0    2018-01-02  for_sale  450000.0  3.0   2.0      0.09   \n",
       "7031.0    2018-01-02  for_sale  450000.0  3.0   2.0      0.09   \n",
       "...              ...       ...       ...  ...   ...       ...   \n",
       "7086.0    2019-12-31  for_sale  919000.0  4.0   2.0       NaN   \n",
       "7086.0    2019-12-31  for_sale  919000.0  4.0   2.0       NaN   \n",
       "7086.0    2019-12-31  for_sale  919000.0  4.0   2.0       NaN   \n",
       "7086.0    2019-12-31  for_sale  919000.0  4.0   2.0       NaN   \n",
       "7086.0    2019-12-31  for_sale  919000.0  4.0   2.0       NaN   \n",
       "\n",
       "                                       full_address         street  \\\n",
       "zip_code                                                             \n",
       "7031.0    15 William St, North Arlington, NJ, 07031  15 William St   \n",
       "7031.0    15 William St, North Arlington, NJ, 07031  15 William St   \n",
       "7031.0    15 William St, North Arlington, NJ, 07031  15 William St   \n",
       "7031.0    15 William St, North Arlington, NJ, 07031  15 William St   \n",
       "7031.0    15 William St, North Arlington, NJ, 07031  15 William St   \n",
       "...                                             ...            ...   \n",
       "7086.0           5 Shippen St, Weehawken, NJ, 07086   5 Shippen St   \n",
       "7086.0           5 Shippen St, Weehawken, NJ, 07086   5 Shippen St   \n",
       "7086.0           5 Shippen St, Weehawken, NJ, 07086   5 Shippen St   \n",
       "7086.0           5 Shippen St, Weehawken, NJ, 07086   5 Shippen St   \n",
       "7086.0           5 Shippen St, Weehawken, NJ, 07086   5 Shippen St   \n",
       "\n",
       "                     city  house_size STATE   A18425  \n",
       "zip_code                                              \n",
       "7031.0    North Arlington         NaN    NJ      0.0  \n",
       "7031.0    North Arlington         NaN    NJ    134.0  \n",
       "7031.0    North Arlington         NaN    NJ    366.0  \n",
       "7031.0    North Arlington         NaN    NJ    663.0  \n",
       "7031.0    North Arlington         NaN    NJ   1989.0  \n",
       "...                   ...         ...   ...      ...  \n",
       "7086.0          Weehawken         NaN    NJ    230.0  \n",
       "7086.0          Weehawken         NaN    NJ    221.0  \n",
       "7086.0          Weehawken         NaN    NJ    438.0  \n",
       "7086.0          Weehawken         NaN    NJ   3032.0  \n",
       "7086.0          Weehawken         NaN    NJ  24460.0  \n",
       "\n",
       "[593111 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e622b5-2209-4ce0-8f23-c9f40f448a4a",
   "metadata": {},
   "source": [
    "# Encode the dataset’s categorical variables using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "caa65310-6b25-4f3d-8dfc-931396015cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of categorical variables \n",
    "categorical_variables = list(df1.dtypes[df1.dtypes == \"object\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29c74aa0-627c-4063-b293-e5abef8191f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sold_date', 'status', 'full_address', 'street', 'city', 'STATE']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(categorical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d64aa3f0-aa1f-467d-a927-97bb2b073851",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b316386b-99b4-4c28-b493-ad18f64171b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 64.0 GiB for an array with shape (593111, 14481) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_variables\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:488\u001b[0m, in \u001b[0;36mOneHotEncoder.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03mFit OneHotEncoder to X, then transform X.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;124;03m    returned.\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_keywords()\n\u001b[1;32m--> 488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:557\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    551\u001b[0m out \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mcsr_matrix(\n\u001b[0;32m    552\u001b[0m     (data, indices, indptr),\n\u001b[0;32m    553\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(n_samples, feature_indices[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m    554\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    555\u001b[0m )\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse:\n\u001b[1;32m--> 557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:1039\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1039\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:1202\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 64.0 GiB for an array with shape (593111, 14481) and data type float64"
     ]
    }
   ],
   "source": [
    "encoded_data = enc.fit_transform(df1[categorical_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dfe33be1-f8d6-46cf-aaeb-9a76541a2a4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m encoded_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mencoded_data\u001b[49m,\n\u001b[0;32m      3\u001b[0m     columns \u001b[38;5;241m=\u001b[39m enc\u001b[38;5;241m.\u001b[39mget_feature_names_out(categorical_variables)\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoded_data' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_df = pd.DataFrame(\n",
    "    encoded_data,\n",
    "    columns = enc.get_feature_names_out(categorical_variables)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "21e67779-87ec-4f00-adbb-1baf6ef54d93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [82]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(\u001b[43mencoded_df\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encoded_df' is not defined"
     ]
    }
   ],
   "source": [
    "display(encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c972c-aff0-405a-919d-77aa7bbb3edf",
   "metadata": {},
   "source": [
    "# Apply Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039267a-2e81-4deb-9438-528e4cc8d0e6",
   "metadata": {},
   "source": [
    "# Split training into testing sets (Create X, or features DataFrame, and create y, or target DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8646f53e-7fec-43fd-85ea-228303bf2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df1[['STATE', 'A18425']]\n",
    "\n",
    "target = df1['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a253d24-3438-48e6-bf2c-5923faec14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, testing_features, training_targets, testing_targets = train_test_split(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76fa4764-81fa-468e-aa2b-d26dd670c492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>A18425</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10027.0</th>\n",
       "      <td>NY</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305.0</th>\n",
       "      <td>NJ</td>\n",
       "      <td>542.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11217.0</th>\n",
       "      <td>NY</td>\n",
       "      <td>111053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285.0</th>\n",
       "      <td>NH</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438.0</th>\n",
       "      <td>NJ</td>\n",
       "      <td>325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019.0</th>\n",
       "      <td>NY</td>\n",
       "      <td>19049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018.0</th>\n",
       "      <td>PA</td>\n",
       "      <td>1580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11207.0</th>\n",
       "      <td>NY</td>\n",
       "      <td>9832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755.0</th>\n",
       "      <td>NJ</td>\n",
       "      <td>10458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12550.0</th>\n",
       "      <td>NY</td>\n",
       "      <td>13265.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444833 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STATE    A18425\n",
       "zip_code                \n",
       "10027.0     NY      90.0\n",
       "7305.0      NJ     542.0\n",
       "11217.0     NY  111053.0\n",
       "3285.0      NH       0.0\n",
       "7438.0      NJ     325.0\n",
       "...        ...       ...\n",
       "10019.0     NY   19049.0\n",
       "19018.0     PA    1580.0\n",
       "11207.0     NY    9832.0\n",
       "7755.0      NJ   10458.0\n",
       "12550.0     NY   13265.0\n",
       "\n",
       "[444833 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d4ead7-1da9-4db0-a43d-57e59ac69325",
   "metadata": {},
   "source": [
    "# Create and use a classifier that can predict whether the house sold price price will be higher or lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbba2854-9919-49df-807c-6fbe103958aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50870ac2-1dd5-4807-b07a-bad081fc0d9b",
   "metadata": {},
   "source": [
    "# Fit: Train the Model by supplying it with some training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fcc34eab-92ec-43a7-a4ca-3e0aa85f1513",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'NY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlogistic_regression_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_targets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1506\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1508\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'NY'"
     ]
    }
   ],
   "source": [
    "logistic_regression_model.fit(training_features, training_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ccc1a4-4768-4e39-8523-d0b84250f52a",
   "metadata": {},
   "source": [
    "# Generate predictions from the model we just fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6384f2f9-537a-45e6-854f-69fd44397f82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'NY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mlogistic_regression_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;124;03m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    427\u001b[0m         indices \u001b[38;5;241m=\u001b[39m (scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:407\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03mPredict confidence scores for samples.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m    this class would be predicted.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    405\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 407\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'NY'"
     ]
    }
   ],
   "source": [
    "predictions = logistic_regression_model.predict(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c059f34-ba5f-4fce-9967-b8777da31a58",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mpredictions\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m\"\u001b[39m: training_targets})\n\u001b[0;32m      2\u001b[0m results_df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": training_targets})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2617e783-bdf0-4743-add0-7defe5848264",
   "metadata": {},
   "source": [
    "# Apply the fitted model to the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0c139e1-4ee9-4ed1-8508-c5ce4902c205",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'MA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m testing_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mlogistic_regression_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;124;03m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;124;03m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    427\u001b[0m         indices \u001b[38;5;241m=\u001b[39m (scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:407\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03mPredict confidence scores for samples.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;124;03m    this class would be predicted.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    405\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 407\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'MA'"
     ]
    }
   ],
   "source": [
    "testing_predictions = logistic_regression_model.predict(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036212c-1be2-417c-a02b-4137944927f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"Testing Data Predictions\": testing_predictions,\n",
    "    \"Testing Data Actual Targets\": testing_targets})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de41ed9-bf66-4494-bdb5-7daaa609fdfc",
   "metadata": {},
   "source": [
    "# Compare each predicted value to its actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c69d7-83a3-49ba-8be0-798ee8e0a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d636f-d4a2-44ca-baba-e31947c92223",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(testing_targets, testing_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17951577-1420-47d4-9a1c-c2565d21502b",
   "metadata": {},
   "source": [
    "# We evaluated the model predictions. If high accuracy (closer to 1) it may ean that there is overfitting which may mean that the model won't perform well on new data it was not trained on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a4933c-b821-4c1a-b040-eacd56787cda",
   "metadata": {},
   "source": [
    "# We can categorize the predictions on higher house prices or lower house prices according to a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288464d-5889-4d9e-b67d-1573e1e0f9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
